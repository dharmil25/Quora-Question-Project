{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, ngrams\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "eng_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "class Quora_class():\n",
    "    def __init__(self):\n",
    "        self.train_df = None\n",
    "\n",
    "    def load_data(self,path):\n",
    "        return pd.read_csv(path,delimiter='\\t',encoding='utf-8')[:50000]\n",
    "    \n",
    "    def common_words(self,x):\n",
    "        q1, q2 = x\n",
    "        return len(set(str(q1).lower().split()) & set(str(q2).lower().split()))\n",
    "\n",
    "    def words_count(self,question):\n",
    "        return len(str(question).split())\n",
    "\n",
    "    def length(self,question):\n",
    "        return len(str(question))\n",
    "\n",
    "    def vect(self,train_df,num):\n",
    "        vectorizer = TfidfVectorizer(stop_words='english', use_idf=True, max_df=0.5, ngram_range=(1, num))\n",
    "        all_questions = pd.concat([train_df[\"question1\"], train_df[\"question2\"]], ignore_index=True)\n",
    "        all_Q = vectorizer.fit_transform(all_questions.values)\n",
    "        Q1 = all_Q[0:int(all_Q.shape[0]/2)]\n",
    "        Q2 = all_Q[int(all_Q.shape[0]/2):]\n",
    "        return pd.Series(np.array([np.dot(Q1[i,:], Q2[i,:].T).A[0,0] for i in range(Q1.shape[0])])).values\n",
    "    \n",
    "    def word_share(self,x):\n",
    "        w1 = set(map(lambda word: word.lower().strip(), str(x['question1']).split(\" \")))\n",
    "        w2 = set(map(lambda word: word.lower().strip(), str(x['question2']).split(\" \")))    \n",
    "        return 1.0 * len(w1 & w2)/(len(w1) + len(w2))\n",
    "\n",
    "\n",
    "    def feature_engineering(self,train_df):\n",
    "        self.train_df = train_df\n",
    "        train_df['q1_words_num'] = train_df['question1'].map(self.words_count)\n",
    "        train_df['q2_words_num'] = train_df['question2'].map(self.words_count)\n",
    "        train_df['q1_length'] = train_df['question1'].map(self.length)\n",
    "        train_df['q2_length'] = train_df['question2'].map(self.length)\n",
    "        train_df['common_words'] = train_df[['question1', 'question2']].apply(self.common_words, axis=1)\n",
    "        train_df['tf_idf_dot_product'] = self.vect(train_df,1)\n",
    "        train_df['tf_idf_2gram_dot_products'] = self.vect(train_df,2)\n",
    "        train_df['word_share'] = self.word_share(train_df)\n",
    "        return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qc = Quora_class()\n",
    "data = qc.load_data('quora_duplicate_questions.tsv')\n",
    "train_df = qc.feature_engineering(data)\n",
    "del train_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_words_num</th>\n",
       "      <th>q2_words_num</th>\n",
       "      <th>q1_length</th>\n",
       "      <th>q2_length</th>\n",
       "      <th>common_words</th>\n",
       "      <th>tf_idf_dot_product</th>\n",
       "      <th>tf_idf_2gram_dot_products</th>\n",
       "      <th>word_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>10</td>\n",
       "      <td>0.981873</td>\n",
       "      <td>0.940866</td>\n",
       "      <td>0.263914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>4</td>\n",
       "      <td>0.774992</td>\n",
       "      <td>0.672048</td>\n",
       "      <td>0.263914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid1  qid2                                          question1  \\\n",
       "0     1     2  What is the step by step guide to invest in sh...   \n",
       "1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "\n",
       "   q1_words_num  q2_words_num  q1_length  q2_length  common_words  \\\n",
       "0            14            12         66         57            10   \n",
       "1             8            13         51         88             4   \n",
       "\n",
       "   tf_idf_dot_product  tf_idf_2gram_dot_products  word_share  \n",
       "0            0.981873                   0.940866    0.263914  \n",
       "1            0.774992                   0.672048    0.263914  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31351\n",
      "18649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(train_df[train_df['is_duplicate']==0]))\n",
    "print(len(train_df[train_df['is_duplicate']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, val = train_test_split(train_df, test_size=0.2)\n",
    "X_sample = train[['q1_words_num','q2_words_num','q1_length','q2_length','common_words','tf_idf_dot_product','tf_idf_2gram_dot_products','word_share']]\n",
    "y_sample = train.is_duplicate\n",
    "X_test = val[['q1_words_num','q2_words_num','q1_length','q2_length','common_words','tf_idf_dot_product','tf_idf_2gram_dot_products','word_share']]\n",
    "y_test = val.is_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using RandomForest 0.7314\n",
      "Logloss using RandomForest 0.4786834621252199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=20,min_samples_split=2,n_estimators=200,random_state=9,max_features='sqrt',min_samples_leaf=4)\n",
    "rf.fit(X_sample,y_sample)\n",
    "accuracy_score = rf.score(X_test,y_test)\n",
    "y_prob=rf.predict_proba(X_test)\n",
    "print(\"Accuracy using RandomForest\",accuracy_score)\n",
    "print(\"Logloss using RandomForest\",log_loss(y_test,y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(0.2343, 'tf_idf_dot_product'), (0.2244, 'tf_idf_2gram_dot_products'), (0.1947, 'common_words'), (0.1106, 'q1_length'), (0.1051, 'q2_length'), (0.0692, 'q2_words_num'), (0.0619, 'q1_words_num'), (0.0, 'word_share')]\n"
     ]
    }
   ],
   "source": [
    "names = X_sample.columns\n",
    "print(\"Features sorted by their score:\")\n",
    "print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using XGBoost 0.7272\n",
      "Logloss using XGBoost 0.4892863171164543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "xgclass=XGBClassifier(max_delta_step=2,base_score=0.5,max_depth=10,n_estimators=200,min_child_weight=2)\n",
    "xgclass.fit(X_sample,y_sample)\n",
    "score = xgclass.score(X_test,y_test)\n",
    "y_predprob=xgclass.predict_proba(X_test)\n",
    "print(\"Accuracy using XGBoost\",score)\n",
    "print(\"Logloss using XGBoost\",log_loss(y_test,y_predprob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.686267\tvalid-logloss:0.686971\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.629629\tvalid-logloss:0.636476\n",
      "[20]\ttrain-logloss:0.588346\tvalid-logloss:0.600405\n",
      "[30]\ttrain-logloss:0.557115\tvalid-logloss:0.573673\n",
      "[40]\ttrain-logloss:0.532893\tvalid-logloss:0.553569\n",
      "[50]\ttrain-logloss:0.513938\tvalid-logloss:0.538542\n",
      "[60]\ttrain-logloss:0.498571\tvalid-logloss:0.52694\n",
      "[70]\ttrain-logloss:0.485935\tvalid-logloss:0.517719\n",
      "[80]\ttrain-logloss:0.475472\tvalid-logloss:0.510693\n",
      "[90]\ttrain-logloss:0.466935\tvalid-logloss:0.505249\n",
      "[100]\ttrain-logloss:0.459906\tvalid-logloss:0.500949\n",
      "[110]\ttrain-logloss:0.453825\tvalid-logloss:0.49766\n",
      "[120]\ttrain-logloss:0.448631\tvalid-logloss:0.494983\n",
      "[130]\ttrain-logloss:0.444379\tvalid-logloss:0.492991\n",
      "[140]\ttrain-logloss:0.440869\tvalid-logloss:0.491453\n",
      "[150]\ttrain-logloss:0.437603\tvalid-logloss:0.490192\n",
      "[160]\ttrain-logloss:0.434374\tvalid-logloss:0.489063\n",
      "[170]\ttrain-logloss:0.432185\tvalid-logloss:0.488178\n",
      "[180]\ttrain-logloss:0.429875\tvalid-logloss:0.4876\n",
      "[190]\ttrain-logloss:0.428082\tvalid-logloss:0.486969\n",
      "[200]\ttrain-logloss:0.426764\tvalid-logloss:0.486608\n",
      "[210]\ttrain-logloss:0.425587\tvalid-logloss:0.48644\n",
      "[220]\ttrain-logloss:0.424186\tvalid-logloss:0.486152\n",
      "[230]\ttrain-logloss:0.422758\tvalid-logloss:0.485837\n",
      "[240]\ttrain-logloss:0.421642\tvalid-logloss:0.485648\n",
      "[250]\ttrain-logloss:0.420496\tvalid-logloss:0.485483\n",
      "[260]\ttrain-logloss:0.419545\tvalid-logloss:0.485269\n",
      "[270]\ttrain-logloss:0.418627\tvalid-logloss:0.485115\n",
      "[280]\ttrain-logloss:0.417758\tvalid-logloss:0.485041\n",
      "[290]\ttrain-logloss:0.416757\tvalid-logloss:0.484858\n",
      "[300]\ttrain-logloss:0.415678\tvalid-logloss:0.484817\n",
      "[310]\ttrain-logloss:0.414485\tvalid-logloss:0.484646\n",
      "[320]\ttrain-logloss:0.412862\tvalid-logloss:0.484562\n",
      "[330]\ttrain-logloss:0.411825\tvalid-logloss:0.48454\n",
      "[340]\ttrain-logloss:0.410901\tvalid-logloss:0.484481\n",
      "[350]\ttrain-logloss:0.410131\tvalid-logloss:0.484456\n",
      "[360]\ttrain-logloss:0.408748\tvalid-logloss:0.484339\n",
      "[370]\ttrain-logloss:0.407416\tvalid-logloss:0.484223\n",
      "[380]\ttrain-logloss:0.40648\tvalid-logloss:0.484185\n",
      "[390]\ttrain-logloss:0.405322\tvalid-logloss:0.484098\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 10\n",
    "params['n_estimators'] = 100\n",
    "params['max_delta_step'] = 5\n",
    "params['base_score'] = 0.5\n",
    "\n",
    "d_train = xgb.DMatrix(X_sample, label=y_sample)\n",
    "d_valid = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=50, verbose_eval=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
